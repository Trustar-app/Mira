# app.py
from graphs.mira_graph import mira_graph
from tools.common.formatters import (
    frontend_inputs_to_state, state_to_frontend_outputs
)
import gradio as gr
import logging
import os

# æ—¥å¿—ç›®å½•
os.makedirs("logs", exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s %(message)s",
    filename="logs/face_detect.log",
    filemode="a",
    encoding="utf-8"
)
# æ§åˆ¶å°åŒæ­¥è¾“å‡º
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter("%(asctime)s %(levelname)s %(name)s %(message)s")
console.setFormatter(formatter)
logging.getLogger().addHandler(console)


def process_user_input(video, audio, text, chat=None):
    markdown = ""
    image = None
    gallery = []
    profile = ""
    products = []

    if chat is None:
        chat = []
    if text:
        chat.append({"role": "user", "content": text})
    if audio:
        chat.append({"role": "user", "content": gr.Audio(audio)})
    if video:
        chat.append({"role": "user", "content": gr.Video(video)})
    yield chat, markdown, image, gallery, profile, products, None, None, ""
    
    for step in mira_graph(frontend_inputs_to_state(video, audio, text, chat)):
        # åŸºäºä¸åŒç»“æœï¼Œåˆ†åˆ«å¤„ç† chatã€markdownã€imageã€galleryã€profileã€products ä¿¡æ¯,å¹¶yieldï¼Œæœ‰çš„æ˜¯ä¸­é—´çš„è¿›åº¦ä¿¡æ¯ï¼Œæœ‰çš„æ˜¯ç»“æœ
        yield state_to_frontend_outputs(step)
        
                

def build_demo():
    with gr.Blocks(theme=gr.themes.Soft(), css=".gradio-container {background: #f8f9fa;} .title {font-size:2.2em;font-weight:bold;color:#d63384;margin-bottom:0.2em;} .subtitle{color:#868e96;}") as demo:
        gr.Markdown("<div class='title'>ğŸ€ Mira æ™ºèƒ½åŒ–å¦†é•œ</div><div class='subtitle'>AIèµ‹èƒ½ä½ çš„ç¾ä¸½æ—¥å¸¸</div>", elem_id="main-title")
        with gr.Row():
            # ç¬¬ä¸€è¡Œï¼šå·¦-è¾“å…¥åŒºï¼Œå³-åé¦ˆåŒº
            with gr.Column(scale=1):
                gr.Markdown("#### ğŸ“¥ ç”¨æˆ·è¾“å…¥åŒº")
                video_in = gr.Video(sources=["webcam"], include_audio=True, label="å½•åˆ¶è§†é¢‘ï¼ˆå«éŸ³é¢‘ï¼‰")
                audio_in = gr.Audio(sources=["microphone"], label="è¯­éŸ³è¾“å…¥")
                text_in = gr.Textbox(label="æ–‡æœ¬è¾“å…¥", lines=2, placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜æˆ–éœ€æ±‚â€¦")
                submit_btn = gr.Button("æäº¤", elem_id="submit-btn")
            with gr.Column(scale=2):
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### ğŸ¤– AIå¯¹è¯åŒº")
                        chat_out = gr.Chatbot(label="AIå¯¹è¯", value=[], type="messages")
                    with gr.Column():
                        gr.Markdown("#### ğŸ§¾ ç»“æ„åŒ–åé¦ˆåŒº")
                        markdown_out = gr.Markdown(label="ç»“æ„åŒ–åˆ†æç»“æœ")
                        image_out = gr.Image(label="åˆ†æå›¾ç‰‡")
                        gallery_out = gr.Gallery(label="åé¦ˆå›¾ç‰‡é›†", columns=4)
        with gr.Row():
            # ç¬¬äºŒè¡Œï¼šå·¦-ç”¨æˆ·æ¡£æ¡ˆï¼Œå³-äº§å“å¡ç‰‡é›†
            with gr.Column():
                gr.Markdown("#### ğŸ“¦ ç”¨æˆ·æ¡£æ¡ˆ")
                profile_out = gr.Markdown("")
            with gr.Column():
                gr.Markdown("#### ğŸ’„ äº§å“å¡ç‰‡é›†")
                products_out = gr.Gallery(label="äº§å“å¡ç‰‡é›†", value=[], columns=2, height=220)
        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            process_user_input,
            inputs=[video_in, audio_in, text_in, chat_out],
            outputs=[chat_out, markdown_out, image_out, gallery_out, profile_out, products_out, video_in, audio_in, text_in]
        )
    return demo

demo = build_demo()

if __name__ == "__main__":
    demo.launch() 